{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction Analysis\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline for predicting customer churn.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Exploration](#data-loading)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "3. [Data Preprocessing](#preprocessing)\n",
    "4. [Model Training](#training)\n",
    "5. [Model Evaluation](#evaluation)\n",
    "6. [Feature Importance Analysis](#features)\n",
    "7. [Business Insights](#insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_preprocessor import DataPreprocessor\n",
    "from model_trainer import ModelTrainer\n",
    "from visualizer import Visualizer\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration {#data-loading}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our classes\n",
    "preprocessor = DataPreprocessor()\n",
    "trainer = ModelTrainer()\n",
    "viz = Visualizer()\n",
    "\n",
    "# Create synthetic customer churn data\n",
    "df = preprocessor.create_synthetic_data(n_samples=10000)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data info\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nChurn distribution:\")\n",
    "print(df['churn'].value_counts())\n",
    "print(f\"\\nChurn rate: {df['churn'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis {#eda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data distributions\n",
    "viz.plot_data_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "viz.plot_correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze churn by categorical variables\n",
    "categorical_cols = ['contract', 'payment_method', 'internet_service', 'paperless_billing']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    churn_rate = df.groupby(col)['churn'].mean()\n",
    "    churn_rate.plot(kind='bar', ax=axes[i], color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Churn Rate by {col.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_ylabel('Churn Rate')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for j, v in enumerate(churn_rate.values):\n",
    "        axes[i].text(j, v + 0.01, f'{v:.2%}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing {#preprocessing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X, y = preprocessor.preprocess_features(df, is_training=True)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names: {list(X.columns)}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = preprocessor.split_data(X, y)\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training {#training}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "print(\"Training multiple models...\")\n",
    "trainer.train_models(X_train, y_train, use_smote=True)\n",
    "print(\"\\nTrained models:\", list(trainer.models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation {#evaluation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "results = trainer.evaluate_all_models(X_test, y_test)\n",
    "\n",
    "# Create results summary\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.drop('confusion_matrix', axis=1)\n",
    "results_df = results_df.round(4)\n",
    "print(\"Model Performance Summary:\")\n",
    "print(results_df.sort_values('roc_auc', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "viz.plot_model_comparison(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "viz.plot_confusion_matrices(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "viz.plot_roc_curves(trainer.models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation results\n",
    "cv_results = trainer.cross_validate_models(X_train, y_train)\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "print(\"Cross-Validation Results (ROC-AUC):\")\n",
    "print(cv_df.sort_values('mean_cv_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis {#features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "rf_importance = trainer.get_feature_importance('random_forest')\n",
    "if rf_importance is not None:\n",
    "    viz.plot_feature_importance(\n",
    "        preprocessor.feature_names, \n",
    "        rf_importance, \n",
    "        'Random Forest Feature Importance'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from XGBoost\n",
    "xgb_importance = trainer.get_feature_importance('xgboost')\n",
    "if xgb_importance is not None:\n",
    "    viz.plot_feature_importance(\n",
    "        preprocessor.feature_names, \n",
    "        xgb_importance, \n",
    "        'XGBoost Feature Importance'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize XGBoost hyperparameters\n",
    "print(\"Optimizing XGBoost hyperparameters...\")\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = preprocessor.split_data(\n",
    "    X_train, y_train, test_size=0.2\n",
    ")\n",
    "\n",
    "best_params, best_score = trainer.optimize_xgboost(\n",
    "    X_train_split, y_train_split, X_val_split, y_val_split, n_trials=20\n",
    ")\n",
    "\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"Best validation score: {best_score:.4f}\")\n",
    "\n",
    "# Evaluate optimized model\n",
    "optimized_results = trainer.evaluate_model(trainer.best_model, X_test, y_test)\n",
    "print(f\"\\nOptimized XGBoost Test ROC-AUC: {optimized_results['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business Insights {#insights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate business impact\n",
    "best_model_name = results_df['roc_auc'].idxmax()\n",
    "best_model = trainer.models[best_model_name]\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "high_risk_threshold = 0.7\n",
    "high_risk_customers = (y_pred_proba >= high_risk_threshold).sum()\n",
    "\n",
    "print(f\"Best performing model: {best_model_name}\")\n",
    "print(f\"Model ROC-AUC: {results[best_model_name]['roc_auc']:.4f}\")\n",
    "print(f\"\\nBusiness Impact Analysis:\")\n",
    "print(f\"- Total test customers: {len(y_test):,}\")\n",
    "print(f\"- Actual churned customers: {y_test.sum():,}\")\n",
    "print(f\"- High-risk customers identified (prob >= {high_risk_threshold}): {high_risk_customers:,}\")\n",
    "print(f\"- Potential intervention rate: {high_risk_customers/len(y_test):.1%}\")\n",
    "\n",
    "# Cost-benefit analysis\n",
    "avg_revenue_per_customer = df['monthly_charges'].mean() * 12  # Annual revenue\n",
    "intervention_cost = 50  # Cost to retain a customer\n",
    "retention_success_rate = 0.3  # 30% success rate for interventions\n",
    "\n",
    "potential_saved_revenue = high_risk_customers * avg_revenue_per_customer * retention_success_rate\n",
    "intervention_cost_total = high_risk_customers * intervention_cost\n",
    "net_benefit = potential_saved_revenue - intervention_cost_total\n",
    "\n",
    "print(f\"\\nCost-Benefit Analysis:\")\n",
    "print(f\"- Average annual revenue per customer: ${avg_revenue_per_customer:.2f}\")\n",
    "print(f\"- Intervention cost per customer: ${intervention_cost:.2f}\")\n",
    "print(f\"- Assumed retention success rate: {retention_success_rate:.0%}\")\n",
    "print(f\"- Potential saved revenue: ${potential_saved_revenue:,.2f}\")\n",
    "print(f\"- Total intervention cost: ${intervention_cost_total:,.2f}\")\n",
    "print(f\"- Net benefit: ${net_benefit:,.2f}\")\n",
    "print(f\"- ROI: {(net_benefit/intervention_cost_total)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights and Recommendations\n",
    "\n",
    "Based on the analysis, here are the key findings:\n",
    "\n",
    "### Model Performance\n",
    "- The best performing model achieved an ROC-AUC score indicating good predictive capability\n",
    "- Multiple algorithms were tested to ensure robustness\n",
    "- Cross-validation confirmed model stability\n",
    "\n",
    "### Important Churn Factors\n",
    "1. **Contract Type**: Month-to-month contracts show higher churn rates\n",
    "2. **Tenure**: Newer customers are more likely to churn\n",
    "3. **Payment Method**: Electronic check users have higher churn\n",
    "4. **Monthly Charges**: Higher charges correlate with increased churn risk\n",
    "\n",
    "### Business Recommendations\n",
    "1. **Retention Strategy**: Focus on month-to-month contract customers\n",
    "2. **Onboarding**: Improve new customer experience in first 12 months\n",
    "3. **Payment Options**: Encourage customers to switch from electronic checks\n",
    "4. **Pricing Strategy**: Review pricing for high-charge customers\n",
    "5. **Proactive Intervention**: Target high-risk customers identified by the model\n",
    "\n",
    "### Implementation\n",
    "- Deploy the model to score customers monthly\n",
    "- Set up automated alerts for high-risk customers\n",
    "- A/B test retention strategies on identified high-risk segments\n",
    "- Monitor model performance and retrain quarterly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}